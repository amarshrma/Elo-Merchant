{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "gc.collect()\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/artgor/elo-eda-and-models\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    ''' \n",
    "    This is done as there are lot of historical data, which requires lot of RAM. \n",
    "    This method  tries to reduce the size of data, it works on only numeric data by selecting the smallest data type\n",
    "    in which it can be represented.\n",
    "    '''\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x): \n",
    "    return np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-pandas-series-dt-date/\n",
    "def getFeaturesFromTrainAndTest(data):\n",
    "\n",
    "    max_dte = data['first_active_month'].dt.date.max()\n",
    "\n",
    "    #Time elapsed since first purchase\n",
    "    data['time_elapsed'] = (max_dte - data['first_active_month'].dt.date).dt.days\n",
    "\n",
    "    #Breaking first_active_month in year and month\n",
    "    data['month'] = data['first_active_month'].dt.month\n",
    "    data['year'] = data['first_active_month'].dt.year\n",
    "    data['day'] = data['first_active_month'].dt.day\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/artgor/elo-eda-and-models\n",
    "def getFeaturesFromTransactionData(data, prefix):\n",
    "\n",
    "    #Breaking purchase date into year,month, day\n",
    "    data['purchase_year'] = data['purchase_date'].dt.year\n",
    "    data['purchase_month'] = data['purchase_date'].dt.month\n",
    "    data['purchase_day'] = data['purchase_date'].dt.day\n",
    "    \n",
    "    data['month_diff'] = ((datetime.datetime.today() - data['purchase_date']).dt.days)//30\n",
    "    data['month_diff'] += data['month_lag']\n",
    "    \n",
    "    data['weekend'] = (data.purchase_date.dt.weekday >=5).astype(int)\n",
    "    data['hour'] = data['purchase_date'].dt.hour\n",
    "    \n",
    "    category2Unique = ['1.0', '2.0', '3.0', '4.0', '5.0', '6.0']\n",
    "    category3Unique = ['1', '2', '3']\n",
    "    \n",
    "    #Converting category_2 and category_3 into indicator variables\n",
    "    #https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "    data = pd.get_dummies(data, columns=['category_2', 'category_3'])\n",
    "    \n",
    "    #this is done to handle missing categorical values incase of test data\n",
    "    for i in range(len(category2Unique)):\n",
    "        name = \"category_2_\" + str(category2Unique[i])\n",
    "        if name not in data.columns:\n",
    "            data[name] = 0\n",
    "        \n",
    "    for i in range(len(category3Unique)):\n",
    "        name = \"category_3_\" + str(category3Unique[i])\n",
    "        if name not in data.columns:\n",
    "            data[name] = 0\n",
    "    \n",
    "    agg_func = {\n",
    "        'authorized_flag': ['sum', 'mean'],\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean', 'sum'],\n",
    "        'category_2_2.0': ['mean', 'sum'],\n",
    "        'category_2_3.0': ['mean', 'sum'],\n",
    "        'category_2_4.0': ['mean', 'sum'],\n",
    "        'category_2_5.0': ['mean', 'sum'],\n",
    "        'category_3_1': ['sum', 'mean'],\n",
    "        'category_3_2': ['sum', 'mean'],\n",
    "        'category_3_3': ['sum', 'mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', std],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', std],\n",
    "        'purchase_month': ['mean', 'max', 'min', std],\n",
    "        'purchase_year': ['mean', 'max', 'min', std],\n",
    "        'purchase_day': ['mean', 'max', 'min', std],\n",
    "        'month_lag': ['min', 'max'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'month_diff': ['min', 'max', 'mean']\n",
    "    }\n",
    "    agg_trans = data.groupby(['card_id']).agg(agg_func)\n",
    "    agg_trans.columns = [prefix + '_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = (data.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format(prefix)))\n",
    "\n",
    "    agg_trans = pd.merge(df, agg_trans, on='card_id', how='left')\n",
    "\n",
    "    return agg_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "    history['installments'] = history['installments'].astype(int)\n",
    "    agg_func = {\n",
    "            'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', std],\n",
    "            'installments': ['count', 'sum', 'mean', 'min', 'max', std],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', std])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesFromMerchantsData(data, prefix):\n",
    "    \n",
    "    salesUnique = ['1', '2', '3', '4', '5']\n",
    "    purchasesUnique = ['1', '2', '3', '4', '5']\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['most_recent_sales_range', 'most_recent_purchases_range'])\n",
    "    \n",
    "     #this is done to handle missing categorical values incase of test data\n",
    "    for i in range(len(salesUnique)):\n",
    "        name = \"most_recent_sales_range_\" + str(salesUnique[i])\n",
    "        if name not in data.columns:\n",
    "            data[name] = 0\n",
    "        \n",
    "    for i in range(len(purchasesUnique)):\n",
    "        name = \"most_recent_purchases_range_\" + str(purchasesUnique[i])\n",
    "        if name not in data.columns:\n",
    "            data[name] = 0\n",
    "            \n",
    "    agg_func = {\n",
    "        'merchant_group_id' : ['nunique'],\n",
    "        'numerical_1' :['sum', 'mean', std],\n",
    "        'numerical_2' :['sum', 'mean', std],\n",
    "        'category_4' :['sum', 'mean', std],\n",
    "        'most_recent_sales_range_1' :['sum', 'mean', std],\n",
    "        'most_recent_sales_range_2' :['sum', 'mean', std],\n",
    "        'most_recent_sales_range_3' :['sum', 'mean', std],\n",
    "        'most_recent_sales_range_4' :['sum', 'mean', std],\n",
    "        'most_recent_sales_range_5' :['sum', 'mean', std],\n",
    "        'most_recent_purchases_range_1' :['sum', 'mean', std],\n",
    "        'most_recent_purchases_range_2' :['sum', 'mean', std],\n",
    "        'most_recent_purchases_range_3' :['sum', 'mean', std],\n",
    "        'most_recent_purchases_range_4' :['sum', 'mean', std],\n",
    "        'most_recent_purchases_range_5' :['sum', 'mean', std],\n",
    "        'avg_sales_lag3' :['sum', 'mean', std],\n",
    "        'avg_purchases_lag3' :['sum', 'mean', std],\n",
    "        'active_months_lag3' :['sum', 'mean', std],\n",
    "        'avg_sales_lag6' :['sum', 'mean', std],\n",
    "        'avg_purchases_lag6' :['sum', 'mean', std],\n",
    "        'active_months_lag6' :['sum', 'mean', std],\n",
    "        'avg_sales_lag12' :['sum', 'mean', std],\n",
    "        'avg_purchases_lag12' :['sum', 'mean', std],\n",
    "        'active_months_lag12' :['sum', 'mean', std],\n",
    "    }\n",
    "    \n",
    "    agg_trans = data.groupby(['card_id']).agg(agg_func)\n",
    "    agg_trans.columns = [prefix + '_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = (data.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format(prefix)))\n",
    "\n",
    "    agg_trans = pd.merge(df, agg_trans, on='card_id', how='left')\n",
    "\n",
    "    return agg_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTheFeatures(data, df_train, df_hist, df_newTrans, df_merchants):\n",
    "    \n",
    "    card_id = data['card_id'].values[0]\n",
    "    #Train Features\n",
    "    trainFeatures = getFeaturesFromTrainAndTest(data)   \n",
    "    df_train['is_rare'] = 0\n",
    "    df_train.loc[df_train['target'] < -30, 'is_rare'] = 1\n",
    "    for f in ['feature_1','feature_2','feature_3']:\n",
    "        mean_encoding = df_train.groupby([f])['is_rare'].mean()\n",
    "        trainFeatures[f] = trainFeatures[f].map(mean_encoding)   \n",
    "    columns_to_drop = ['first_active_month']\n",
    "    trainFeatures = trainFeatures.drop(columns_to_drop, axis = 1)\n",
    "    \n",
    "    #historical Transaction Features\n",
    "    df_hist = df_hist[df_hist['card_id'] == card_id] #selecting only relevant card_ids\n",
    "    historicalTransactionFeatures = getFeaturesFromTransactionData(df_hist, prefix = 'hist_Trans_')\n",
    "    historicalTransactionFeaturesMonth = aggregate_per_month(df_hist)\n",
    "    \n",
    "    #New Transaction Features\n",
    "    df_newTrans = df_newTrans[df_newTrans['card_id'] == card_id] #selecting only relevant card_ids\n",
    "    newTransactionFeatures = getFeaturesFromTransactionData(df_newTrans, prefix = 'new_Trans_')\n",
    "    newTransactionFeaturesMonth = aggregate_per_month(df_newTrans)\n",
    "    \n",
    "    #merchants features\n",
    "    allTransactions = pd.concat([df_hist, df_newTrans], axis = 0)\n",
    "    columns_to_drop = ['merchant_category_id', 'subsector_id', 'city_id', 'state_id', 'category_2', 'category_1']\n",
    "    allTransactions = allTransactions.drop(columns_to_drop, axis = 1)\n",
    "    df_merchants = df_merchants.drop(columns_to_drop, axis = 1)\n",
    "    del df_hist, df_newTrans\n",
    "    gc.collect()\n",
    "    df_merchants_trans = pd.merge(allTransactions, df_merchants, on='merchant_id', how='left')\n",
    "    del allTransactions\n",
    "    gc.collect()\n",
    "    merchantsFeatures = getFeaturesFromMerchantsData(df_merchants_trans, prefix = 'merchant_')\n",
    "    del df_merchants_trans\n",
    "    \n",
    "    #merging all the data\n",
    "    gc.collect()\n",
    "    train = pd.merge(trainFeatures, historicalTransactionFeatures, on='card_id',how='left')\n",
    "    train = pd.merge(train, newTransactionFeatures, on='card_id', how = 'left')\n",
    "    train = pd.merge(train, historicalTransactionFeaturesMonth, on = 'card_id', how = 'left')\n",
    "    train = pd.merge(train, newTransactionFeaturesMonth, on = 'card_id', how = 'left')\n",
    "    train = pd.merge(train, merchantsFeatures, on = 'card_id', how='left')    \n",
    "    del trainFeatures, newTransactionFeatures, newTransactionFeaturesMonth, historicalTransactionFeatures, historicalTransactionFeaturesMonth, merchantsFeatures\n",
    "    \n",
    "    #Handling inf values\n",
    "    train.replace([-np.inf,np.inf], np.nan, inplace=True)\n",
    "    try:\n",
    "        train['new_Trans_transactions_count'].fillna(train['new_Trans_transactions_count'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_authorized_flag_sum'].fillna(train['new_Trans_authorized_flag_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_authorized_flag_mean'].fillna(train['new_Trans_authorized_flag_mean'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_1_sum'].fillna(train['new_Trans_category_1_sum'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_1_mean'].fillna(train['new_Trans_category_1_mean'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_1.0_mean'].fillna(train['new_Trans_category_2_1.0_mean'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass  \n",
    "    try:\n",
    "        train['new_Trans_category_2_1.0_sum'].fillna(train['new_Trans_category_2_1.0_sum'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_2.0_mean'].fillna(train['new_Trans_category_2_2.0_mean'].mode()[0], inplace=True)\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_2.0_sum'].fillna(train['new_Trans_category_2_2.0_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_3.0_mean'].fillna(train['new_Trans_category_2_3.0_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_3.0_sum'].fillna(train['new_Trans_category_2_3.0_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_4.0_mean'].fillna(train['new_Trans_category_2_4.0_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_4.0_sum'].fillna(train['new_Trans_category_2_4.0_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_5.0_sum'].fillna(train['new_Trans_category_2_5.0_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_2_5.0_mean'].fillna(train['new_Trans_category_2_5.0_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_1_sum'].fillna(train['new_Trans_category_3_1_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_1_mean'].fillna(train['new_Trans_category_3_1_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_2_sum'].fillna(train['new_Trans_category_3_2_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_2_mean'].fillna(train['new_Trans_category_3_2_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_3_sum'].fillna(train['new_Trans_category_3_3_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_category_3_3_mean'].fillna(train['new_Trans_category_3_3_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_merchant_id_nunique'].fillna(train['new_Trans_merchant_id_nunique'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_amount_sum'].fillna(train['new_Trans_purchase_amount_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_amount_mean'].fillna(train['new_Trans_purchase_amount_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_amount_max'].fillna(train['new_Trans_purchase_amount_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_amount_min'].fillna(train['new_Trans_purchase_amount_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_amount_std'].fillna(train['new_Trans_purchase_amount_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_installments_sum'].fillna(train['new_Trans_installments_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_installments_mean'].fillna(train['new_Trans_installments_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_installments_max'].fillna(train['new_Trans_installments_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_installments_min'].fillna(train['new_Trans_installments_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_installments_std'].fillna(train['new_Trans_installments_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_month_mean'].fillna(train['new_Trans_purchase_month_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_month_max'].fillna(train['new_Trans_purchase_month_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_month_min'].fillna(train['new_Trans_purchase_month_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_month_std'].fillna(train['new_Trans_purchase_month_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_year_mean'].fillna(train['new_Trans_purchase_year_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_year_max'].fillna(train['new_Trans_purchase_year_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_year_min'].fillna(train['new_Trans_purchase_year_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_year_std'].fillna(train['new_Trans_purchase_year_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_day_mean'].fillna(train['new_Trans_purchase_day_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_day_max'].fillna(train['new_Trans_purchase_day_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_day_min'].fillna(train['new_Trans_purchase_day_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_purchase_day_std'].fillna(train['new_Trans_purchase_day_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_month_lag_min'].fillna(train['new_Trans_month_lag_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_month_lag_max'].fillna(train['new_Trans_month_lag_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_merchant_category_id_nunique'].fillna(train['new_Trans_merchant_category_id_nunique'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_state_id_nunique'].fillna(train['new_Trans_state_id_nunique'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_subsector_id_nunique'].fillna(train['new_Trans_subsector_id_nunique'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_city_id_nunique'].fillna(train['new_Trans_city_id_nunique'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag3_sum'].fillna(train['merchant_avg_purchases_lag3_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag3_std'].fillna(train['merchant_avg_purchases_lag3_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag6_sum'].fillna(train['merchant_avg_purchases_lag6_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag6_std'].fillna(train['merchant_avg_purchases_lag6_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag12_sum'].fillna(train['merchant_avg_purchases_lag12_sum'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['merchant_avg_purchases_lag12_std'].fillna(train['merchant_avg_purchases_lag12_std'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_month_diff_min'].fillna(train['new_Trans_month_diff_min'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_month_diff_max'].fillna(train['new_Trans_month_diff_max'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['new_Trans_month_diff_mean'].fillna(train['new_Trans_month_diff_mean'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['month_lag_mean_y'].fillna(train['month_lag_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['month_lag_std_y'].fillna(train['month_lag_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_count_mean_y'].fillna(train['purchase_amount_count_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_count_std_y'].fillna(train['purchase_amount_count_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_sum_mean_y'].fillna(train['purchase_amount_sum_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_sum_std_y'].fillna(train['purchase_amount_sum_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_mean_mean_y'].fillna(train['purchase_amount_mean_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_mean_std_y'].fillna(train['purchase_amount_mean_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_min_mean_y'].fillna(train['purchase_amount_min_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_min_std_y'].fillna(train['purchase_amount_min_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_max_mean_y'].fillna(train['purchase_amount_max_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_max_std_y'].fillna(train['purchase_amount_max_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_std_mean_y'].fillna(train['purchase_amount_std_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_sum_mean_y'].fillna(train['purchase_amount_sum_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['purchase_amount_std_std_y'].fillna(train['purchase_amount_std_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_count_mean_y'].fillna(train['installments_count_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_count_std_y'].fillna(train['installments_count_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_sum_mean_y'].fillna(train['installments_sum_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_sum_std_y'].fillna(train['installments_sum_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_mean_mean_y'].fillna(train['installments_mean_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_mean_std_y'].fillna(train['installments_mean_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_min_mean_y'].fillna(train['installments_min_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_min_std_y'].fillna(train['installments_min_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_max_mean_y'].fillna(train['installments_max_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_max_std_y'].fillna(train['installments_max_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_std_mean_y'].fillna(train['installments_std_mean_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        train['installments_std_std_y'].fillna(train['installments_std_std_y'].mode()[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    train = train.drop(['target', 'card_id'], axis = 1)\n",
    "\n",
    "    return train\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(data):\n",
    "    df_train = reduce_mem_usage(pd.read_csv(\"train_EDA.csv\", parse_dates=['first_active_month']))\n",
    "    df_hist = reduce_mem_usage(pd.read_csv(\"histTrans_EDA.csv\", parse_dates=['purchase_date']))\n",
    "    df_newTrans = reduce_mem_usage(pd.read_csv(\"newTrans_EDA.csv\", parse_dates=['purchase_date']))\n",
    "    df_merchants = reduce_mem_usage(pd.read_csv(\"merchants_EDA.csv\"))\n",
    "    \n",
    "    allFeatures = getAllTheFeatures(data, df_train, df_hist, df_newTrans, df_merchants)\n",
    "    print(allFeatures.shape)\n",
    "    clf = joblib.load('finalModel.pkl')\n",
    "    prediction = clf.predict(allFeatures)\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X,Y):\n",
    "    y_pred = final_fun_1(X)\n",
    "    print(\"Actual Loyalty Score:\", Y[0])\n",
    "    print(\"Predicted Loyalty Score:\", y_pred)\n",
    "    print(\"Root mean squared error: {}\".format(np.sqrt(mean_squared_error(Y, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(pd.read_csv(\"train_EDA.csv\", parse_dates=['first_active_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to 1166.08 Mb (62.5% reduction)\n",
      "Mem. usage decreased to 74.88 Mb (64.3% reduction)\n",
      "Mem. usage decreased to 15.64 Mb (72.2% reduction)\n",
      "(1, 233)\n",
      "Actual Loyalty Score: 0.646\n",
      "Predicted Loyalty Score: [-0.52284553]\n",
      "Root mean squared error: 1.1688416275640034\n",
      "CPU times: user 57 s, sys: 6.21 s, total: 1min 3s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "final_fun_2(df_train[0:1], df_train['target'][0:1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
